{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809fa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from requests.compat import urljoin, urlencode\n",
    "from rich.progress import track\n",
    "from typing import List, Dict\n",
    "from uau_api import UauAPI\n",
    "from uau_api.settings import Settings\n",
    "from uau_api.utils import save_base64_to_file, write_jsonl\n",
    "import aiofiles\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import dateutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "# Initialize the client\n",
    "uau = UauAPI(Settings().API_URL, Settings().API_KEY)\n",
    "wd  = Path(Settings().WORKDIR)\n",
    "uau.authenticate('leonardo', 'hybr01')\n",
    "url = urljoin(Settings().API_URL, 'Obras/ObterObrasAtivas')\n",
    "async def fetch_content():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.request(method='POST', url=url, headers=uau.session.headers) as response:\n",
    "            if response.status == 200:\n",
    "                return await response.read()\n",
    "            else:\n",
    "                return f\"Error: {response.status}\"\n",
    "content = await fetch_content()\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffd105",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = urljoin(Settings().API_URL, 'Obras/ObterObrasAtivas')\n",
    "requests.post(url, headers=uau.session.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c32550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(empresa: int, obra: str, processo: str) -> List[Dict]:\n",
    "    return uau.Anexo.retornar_arquivos_em_lista_bytes(\n",
    "        empresa, f\"PROCESSO {processo}-{obra}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def load_jsonl(jsonl: str | Path):\n",
    "    file_content = []\n",
    "    with open(jsonl) as fc:\n",
    "        json_file = [json.loads(line) for line in fc.readlines()]\n",
    "        file_content.extend(json_file)\n",
    "    return file_content\n",
    "\n",
    "\n",
    "def remove_duplicate_dicts(list_of_dicts):\n",
    "    return [dict(t) for t in {tuple(d.items()) for d in list_of_dicts}]\n",
    "\n",
    "\n",
    "def url_encode(file: str) -> str:\n",
    "    base_url = \"https://hybrazil.sharepoint.com/sites/DataScience/Documentos%20Compartilhados/Forms/AllItems.aspx\"\n",
    "    root_dir = \"/sites/DataScience/Documentos Compartilhados/NotasUAU/\"\n",
    "    params = dict(\n",
    "        id=f\"{root_dir}{file}\",\n",
    "        viewid=\"5b892423-10db-4b4f-a8f9-f0bdeafd317e\",\n",
    "        parent=root_dir,\n",
    "    )\n",
    "    encoded = urlencode(params)\n",
    "    return f\"{base_url}?{encoded}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3773d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(load_jsonl(wd / 'NotasUAU/downloaded.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1362e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpf_cnpj = df['CNPJCPFFornecedor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70ede93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_string_in_dict_values(data: dict, search_string: str) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if any value in a dictionary contains a given partial string.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The dictionary to search within.\n",
    "        search_string (str): The partial string to search for.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the partial string is found in any value, False otherwise.\n",
    "    \"\"\"\n",
    "    for value in data.values():\n",
    "        if search_string in value:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fbe0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "htm = df[['Empresa', 'Obra', 'Processos', 'url']].explode('Processos').map(lambda x: x.get('Numero') if isinstance(x, dict) else x)\n",
    "htm['item_index'] = htm.groupby(['Empresa', 'Obra', 'Processos']).cumcount()\n",
    "htm['item_url'] = htm.apply(lambda x: f'<a href=\"{x['url']}\">Arquivo-{x['item_index'] + 1}</a>', axis=1)\n",
    "display(HTML(\n",
    "    htm.query('Empresa==322').drop(columns='url').to_html(escape=False)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff231d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_file(273, '420A', 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e033aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nfe_entrada_jsonl = []\n",
    "for file in (wd / 'NotasUAU/json_files').glob('*.jsonl'):\n",
    "    content = load_jsonl(file)\n",
    "    nfe_entrada_jsonl.extend(content)\n",
    "    \n",
    "nfe_entrada = pd.json_normalize(nfe_entrada_jsonl)\n",
    "nfe_entrada = nfe_entrada.filter(regex='^(?!NotaFiscal).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ebe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected = load_jsonl(wd / 'NotasUAU/collected.jsonl')\n",
    "collected_df = pd.DataFrame(collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfe_entrada[\"to_download\"] = nfe_entrada[\"Processos\"].apply(\n",
    "    lambda x: remove_duplicate_dicts(\n",
    "        [\n",
    "            dict(Empresa=p[\"Empresa\"], Obra=p[\"Obra\"], Processo=p[\"Numero\"])\n",
    "            for p in x\n",
    "            if isinstance(x, list)\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608367ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded = load_jsonl(wd / 'NotasUAU/downloaded.jsonl')\n",
    "downloaded = pd.DataFrame(downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not downloaded.empty:\n",
    "    cols = ['Empresa', 'Obra', 'Numero', 'CodigoFornecedor', 'NumeroNotaFiscal', ]\n",
    "    indexes_df1 = nfe_entrada.set_index(cols).index\n",
    "    indexes_df2 = downloaded.set_index(cols).index\n",
    "\n",
    "    indexes_df1.isin(indexes_df2)\n",
    "    nfe_entrada = nfe_entrada[~indexes_df1.isin(indexes_df2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4450367",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = nfe_entrada.filter(regex=re.compile('data', re.IGNORECASE)).columns\n",
    "nfe_entrada[columns] = nfe_entrada[columns].map(dateutil.parser.parse)\n",
    "idx = nfe_entrada['ChaveNotaFiscalEletronica'].replace('', pd.NA).isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "async def async_download_file(session: aiohttp.ClientSession, method: str, url: str, *args, **kwargs) -> bytes:\n",
    "    try:\n",
    "        async with session.request(method=method, url=url, *args, **kwargs) as response:\n",
    "            if response.status == 200:\n",
    "                return await response.read()\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "async def async_save_to_file(file_content: bytes, file_type: str, destination: Path|str, mode: str) -> None:\n",
    "    \n",
    "    if mode not in ('a', 'w', 'wb'):\n",
    "        return\n",
    "    \n",
    "    if isinstance(destination, str):\n",
    "        destination = Path(destination)\n",
    "        \n",
    "    if content is None:\n",
    "        return\n",
    "\n",
    "    destination.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if file_type == 'image':\n",
    "        try:\n",
    "            file_bytes = base64.b64decode(file_content)\n",
    "            async with aiofiles.open(destination, mode=mode) as file:\n",
    "                await file.write(file_bytes)\n",
    "        except Exception as e:\n",
    "            e\n",
    "    if file_type == 'json':\n",
    "        async with aiofiles.open(destination, mode=mode) as file:\n",
    "                await file.write(file_bytes)\n",
    "\n",
    "\n",
    "async def process(session: aiohttp.ClientSession, url: str, destination: Path | str) -> None:\n",
    "    \"\"\" \"\"\"\n",
    "    if isinstance(destination, str):\n",
    "        destination = Path(destination)\n",
    "\n",
    "    content = await async_download_file(session, url)\n",
    "    await async_save_to_file(content, destination)\n",
    "    await asyncio.sleep(random.uniform(0.1, 0.3))\n",
    "\n",
    "    \n",
    "async def main(data: list[dict], column: str, destination: str):\n",
    "    destination = Path(destination)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for row in data:\n",
    "            link = urljoin(url, row[column])\n",
    "            task = asyncio.create_task(process(session, link, destination))\n",
    "            tasks.append(task)\n",
    "            \n",
    "            # Process in chunks to avoid overwhelming the server\n",
    "            if len(tasks) >= 10:\n",
    "                await asyncio.gather(*tasks)\n",
    "                tasks = []\n",
    "\n",
    "        if tasks:\n",
    "            await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88aa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in nfe_entrada[~idx].iloc[-1:].explode(\"to_download\").dropna(subset='to_download').iterrows():\n",
    "    empresa = row[\"Empresa\"]\n",
    "    obra = row[\"Obra\"]\n",
    "    processo = row[\"to_download\"].get(\"Processo\")\n",
    "    data_formatada = row[\"DataEmissao\"].strftime(\"%Y-%m-%d\")\n",
    "    cpf_cnpj_ornecedor = row[\"CNPJCPFFornecedor\"]\n",
    "    numero_nota_fiscal = row[\"NumeroNotaFiscal\"]\n",
    "    dir_name = f\"{row['DataEmissao'].year}/{row['DataEmissao'].month:02d}/{row['DataEmissao'].day:02d}/{empresa}-{obra}\"\n",
    "    destination = wd / f\"NotasUAU/{dir_name}\"\n",
    "    response = get_file(*row[\"to_download\"].values())\n",
    "    if isinstance(response, list):\n",
    "        print(row[\"to_download\"].values())\n",
    "        for item in response:\n",
    "            conteudo = item[\"ConteudoArquivo\"]\n",
    "            extensao_arquivo = Path(item[\"NomeArquivo\"]).suffix.lower()\n",
    "            file_name = (\n",
    "                f\"{empresa}-\"\n",
    "                f\"{obra}-\"\n",
    "                f\"{processo}-\"\n",
    "                f\"{data_formatada}-\"\n",
    "                f\"{cpf_cnpj_ornecedor}-\"\n",
    "                f\"{numero_nota_fiscal}-\"\n",
    "                f\"{extensao_arquivo}\"\n",
    "            )\n",
    "            file_location = destination / f\"{file_name}\"\n",
    "            save_base64_to_file(\n",
    "                base64_string=item[\"ConteudoArquivo\"],\n",
    "                output_filename=file_location\n",
    "            )\n",
    "            url = url_encode(str(file_location).split('NotasUAU/')[-1])\n",
    "            row[columns] = row[columns].map(lambda x: x.strftime('%Y-%m-%d'))\n",
    "            line = row.to_dict() | dict(url=url)\n",
    "            \n",
    "            write_jsonl(line, wd / 'NotasUAU/downloaded.jsonl', mode='a')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4a8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
